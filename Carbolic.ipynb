{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66a23d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "OpenAI.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ce4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2c4ad5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_assistant(client, name, instructions, files=None):\n",
    "\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=name,\n",
    "        instructions=instructions,\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        tools=[{\"type\": \"retrieval\"}],\n",
    "        file_ids=[prepare_file(f).id for f in files]\n",
    "    )\n",
    "    \n",
    "    return assistant\n",
    "\n",
    "def prepare_file(client, path):\n",
    "    file = client.files.create(\n",
    "        file=path,\n",
    "        purpose='assistants'\n",
    "    )\n",
    "    return file\n",
    "\n",
    "def create_thread(client):\n",
    "    thread = client.beta.threads.create()\n",
    "    \n",
    "    return thread\n",
    "\n",
    "def send_message(client, thread, user_message):\n",
    "    \n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id = thread.id,\n",
    "        role=\"user\",\n",
    "        content=user_message\n",
    "    )\n",
    "    \n",
    "    log = last_message(client, thread)\n",
    "    \n",
    "    return message, log\n",
    "\n",
    "def start_run(client, thread, assistant):\n",
    "    \n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        tools=[{\"type\": \"retrieval\"}]\n",
    "    )\n",
    "    \n",
    "    return run\n",
    "\n",
    "def retrieve_run(client, thread, run):\n",
    "    \n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "    \n",
    "    return run\n",
    "\n",
    "def generate_response(client, thread, assistant):\n",
    "    run = start_run(client, thread, assistant)\n",
    "\n",
    "    while run.status != 'completed':\n",
    "        run = retrieve_run(thread, run)\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    log = last_message(client, thread)\n",
    "        \n",
    "    return run, log\n",
    "\n",
    "def last_message(client, thread):\n",
    "    messages = client.beta.threads.messages.list(\n",
    "      thread_id=thread.id\n",
    "    )\n",
    "    last_msg = messages.dict()['data'][0]\n",
    "    \n",
    "    role = last_msg['role']\n",
    "    content = last_msg['content'][0]['text']['value']\n",
    "    \n",
    "    return {'role': role, 'content': content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d3fff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_name = 'Carbolic'\n",
    "assistant_instructions = \"\"\"\n",
    "You are a legal assistant chatbot. Use your knowledge to perform tasks such as proofreading and answer retrieval to help your solicitor perform their tasks to the highest quality.\n",
    "\"\"\"\n",
    "assistant_files=['/Users/kaihayden/Desktop/notes_example.txt']\n",
    "\n",
    "assistant = create_assistant(name=assistant_name, instructions=assistant_instructions, files=assistant_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "590855af",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = create_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a3137534",
   "metadata": {},
   "outputs": [],
   "source": [
    "message, log = send_message(thread, \"Can you proofread this and point out any grammatical or spelling mistakes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "55b2cf54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued\n",
      "queued\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n",
      "in_progress\n"
     ]
    }
   ],
   "source": [
    "run, log = generate_response(thread, assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2ade485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name, content = last_message(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d417dd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upon reviewing the document, here are the grammatical and spelling errors found in the first 29% of the text:\n",
      "\n",
      "1. \"Logicism and Probabilism Epistemology has traditionally distinguished ...\" should have a colon or dash after \"Probabilism\":\n",
      "   - \"Logicism and Probabilism: Epistemology has traditionally distinguished ...\"\n",
      "\n",
      "2. \"... from intuition- Empiricism derived new knowledge ...\" should have a period instead of a dash:\n",
      "   - \"from intuition. Empiricism derived new knowledge ...\"\n",
      "\n",
      "3. \"Rationalism and empiricism were opposing theories but ...\" should have a comma before \"but\":\n",
      "   - \"Rationalism and empiricism were opposing theories, but ...\"\n",
      "\n",
      "4. \"Deductions can be made public and checked against each other intuitions are ...\" should have a semicolon or period, and a comma is needed after \"other\":\n",
      "   - \"Deductions can be made public and checked against each other; intuitions are ...\"\n",
      "\n",
      "5. In \"There are two major varieties of rationalism- logicism a descendant ...\" commas should separate the list items:\n",
      "   - \"There are two major varieties of rationalism: logicism, a descendant ...\"\n",
      "\n",
      "6. The list: \"1. Apply rationality to itself. Use logic to prove that logic works and therefore is rational ...\" should be formatted as an actual list or have clearer separation between points.\n",
      "\n",
      "7. \"Unfortunately we failed at step 1.\" should have a comma after \"Unfortunately\":\n",
      "   - \"Unfortunately, we failed at step 1.\"\n",
      "\n",
      "8. \"It failed around 1960 and was the last serious attempt to build ...\" should have a comma after \"1960\":\n",
      "   - \"It failed around 1960, and was the last serious attempt to build ...\"\n",
      "\n",
      "9. \"Logic is inherently broken nothing can be done about it.\" should have a semicolon or period:\n",
      "   - \"Logic is inherently broken; nothing can be done about it.\"\n",
      "\n",
      "10. \"... limitations to what can be known produced the crisis ...\" should have \"limitations on\" rather than \"limitations to\":\n",
      "    - \"... limitations on what can be known produced the crisis ...\"\n",
      "\n",
      "11. \"The issue with the scientific understanding is the world is that it does ...\" should be clarified:\n",
      "    - \"The issue with the scientific understanding of the world is that it does ...\"\n",
      "\n",
      "12. \"Some epistemologists proceeded to develop probability theory as a tool for understanding what being “more confident” ...\" should use 'what \"being more confident\"' without space:\n",
      "    - \"Some epistemologists proceeded to develop probability theory as a tool for understanding 'what \"being more confident\"' ...\"\n",
      "\n",
      "13. \"Typical discussions of rationalism’s collapse cover only1.\" should separate \"only\" and \"1.\" with a space:\n",
      "    - \"Typical discussions of rationalism’s collapse cover only 1.\"\n",
      "\n",
      "14. \"For over two thousand years rationalist philosophers held the Aristotelian view of logic:- You have a list of sentences ...\" should have a line break before the list, and each item should begin with a capital letter:\n",
      "    - For over two thousand years rationalist philosophers held the Aristotelian view of logic:\n",
      "        - You have a list of sentences ...\n",
      "\n",
      "15. \"What if a clear answer isn’t available? (eg. I’m not sure)- What if ...\" should have periods after each example, and \"e.g.,\" should be used instead of \"eg.\":\n",
      "    - \"What if a clear answer isn’t available? (e.g., I’m not sure). What if ...\"\n",
      "\n",
      "16. \"Is “America” something that could be true or false?\" should have the question mark inside the quotation mark if it's part of the quoted material:\n",
      "    - \"Is \"America\" something that could be true or false?\"\n",
      "\n",
      "17. \"So clearly Aristotelian theory contradicts with logical epistemology.\" should use \"contradicts\" without \"with\":\n",
      "    - \"So clearly Aristotelian theory contradicts logical epistemology.\"\n",
      "\n",
      "There may be additional errors further in the document, which would need to be checked in turn. Would you like me to continue proofreading the rest of the document?\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c685b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30310fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
